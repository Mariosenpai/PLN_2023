{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:13:14.001800200Z",
     "start_time": "2023-10-25T01:13:13.277978300Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk.lm.models import Lidstone\n",
    "from nltk.lm.models import Laplace\n",
    "from nltk.corpus import machado\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "def remover_stopwords(texto):\n",
    "    # Carregue a lista de stopwords da língua desejada (exemplo: português)\n",
    "    stopwords_lista = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    # Tokenize o texto em palavras\n",
    "    palavras = word_tokenize(texto)\n",
    "    \n",
    "    # Crie uma lista de palavras sem as stopwords\n",
    "    palavras_sem_stopwords = [palavra for palavra in palavras if palavra.lower() not in stopwords_lista]\n",
    "    \n",
    "    # Recrie o texto sem as stopwords\n",
    "    texto_sem_stopwords = ' '.join(palavras_sem_stopwords)\n",
    "    \n",
    "    return texto_sem_stopwords\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "    words = text.split()\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - n + 1):\n",
    "        bigram =  \" \".join(words[i:i+n]) \n",
    "        bigrams.append(tuple(bigram.split())) \n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "def remocao_caracteres_especiais(text):\n",
    "    padrao = r'[^\\w]+'\n",
    "    return re.sub(padrao, ' ', text)\n",
    "\n",
    "def trans_corpus_text(corpus):\n",
    "    text = ''\n",
    "    for i in corpus:\n",
    "        text += machado.raw(i) +' '\n",
    "    \n",
    "    #Pre-processamento\n",
    "    text = remover_stopwords(text)\n",
    "    text = remocao_caracteres_especiais(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def criar_modelo(text,n, model=None, gamma=0.1):\n",
    "    tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(text)]\n",
    "    train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "    \n",
    "    if model == 'li':\n",
    "        mo = Lidstone(gamma,order=n )\n",
    "    elif model == 'la':\n",
    "        mo = Laplace(order=n)\n",
    "    else:\n",
    "        mo = MLE(n)\n",
    "        \n",
    "    mo.fit(train_data, padded_sents)\n",
    "    return mo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:05:14.224797700Z",
     "start_time": "2023-10-25T02:05:14.221285100Z"
    }
   },
   "id": "48d71d8e3c4692b0"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "corpus = machado.fileids()\n",
    "c = trans_corpus_text(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:23:48.820567200Z",
     "start_time": "2023-10-25T01:23:34.689542100Z"
    }
   },
   "id": "e21f20110f5e363c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model = criar_modelo(c,1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:24:30.964769900Z",
     "start_time": "2023-10-25T01:24:24.634118600Z"
    }
   },
   "id": "89254627946ee072"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "vocabulario = model.vocab.counts\n",
    "total_palavras = len(c.split())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:37:25.141468600Z",
     "start_time": "2023-10-25T01:37:25.019506100Z"
    }
   },
   "id": "4fd7275c315f5ac4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0d13b00b94f4173"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "['conto',\n 'contos',\n 'fluminenses',\n '1870',\n 'texto',\n 'fonte',\n 'obra',\n 'completa',\n 'machado',\n 'assis']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binario = []\n",
    "for palavra in vocabulario:\n",
    "    binario.append(palavra)\n",
    "binario[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:33:39.531313800Z",
     "start_time": "2023-10-25T01:33:39.515865200Z"
    }
   },
   "id": "7a666115db794ac8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "B) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e66fd14fe00dcff"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "17030"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contagem(vocabulario):\n",
    "    dic_contagem = {}\n",
    "    for palavra in vocabulario:\n",
    "        dic_contagem[palavra] = vocabulario.get(palavra)\n",
    "    return dic_contagem\n",
    "contagem(vocabulario)['se']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:44:29.688436700Z",
     "start_time": "2023-10-25T01:44:29.663651Z"
    }
   },
   "id": "cd66eef9745d1fdf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "C)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42ce1515115a92d4"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0118481269106235\n"
     ]
    }
   ],
   "source": [
    "def frequencia(vocabulario):\n",
    "    dic_frequencia = {}\n",
    "    for palavra in vocabulario:\n",
    "        frequencia = vocabulario.get(palavra)/total_palavras\n",
    "        dic_frequencia[palavra] = f'{frequencia: .16f}'\n",
    "    return dic_frequencia\n",
    "\n",
    "print(frequencia(vocabulario)['se'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:58:22.654514400Z",
     "start_time": "2023-10-25T01:58:22.602610400Z"
    }
   },
   "id": "9cd1f2dd8979929d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "D)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "957c920deb5ea16f"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "'-0.1665347934001532'"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frequencia_inversa(vocabulario):\n",
    "    dic_frequencia_inversa = {}\n",
    "    for palavra in vocabulario:\n",
    "        frequencia = vocabulario.get(palavra)/total_palavras\n",
    "        frequencia_inversa = frequencia * math.log2(1/vocabulario.get(palavra))\n",
    "        dic_frequencia_inversa[palavra] = f'{frequencia_inversa: .16f}'\n",
    "    return dic_frequencia_inversa\n",
    "frequencia_inversa(vocabulario)['se']\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T01:53:49.530214100Z",
     "start_time": "2023-10-25T01:53:49.466609900Z"
    }
   },
   "id": "5219841a771fc422"
  },
  {
   "cell_type": "markdown",
   "source": [
    "E) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64727a4364b407ca"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "bigram = generate_ngrams(c,2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:11:51.469571700Z",
     "start_time": "2023-10-25T02:11:50.783321600Z"
    }
   },
   "id": "524ab0cf1afe5c55"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "1067246"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(bigram))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:36:40.557832Z",
     "start_time": "2023-10-25T02:36:40.354832900Z"
    }
   },
   "id": "ce88ba696b36099c"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "1437357"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:25:57.231609800Z",
     "start_time": "2023-10-25T02:25:57.221623500Z"
    }
   },
   "id": "ad79a3b8c20358c1"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def frequencia_ngram(ngram):\n",
    "    contagem1 = Counter(set(ngram))\n",
    "    contagem2 = Counter(ngram)\n",
    "    \n",
    "    # Subtrair a contagem de lista2 da contagem de lista1\n",
    "    bigram_repetidos = list((contagem2 - contagem1).elements())\n",
    "    \n",
    "    \n",
    "    dic_freq = {}\n",
    "    for b in set(ngram):\n",
    "        dic_freq[b] = 1\n",
    "    \n",
    "    for b in bigram_repetidos:\n",
    "        dic_freq[b] += 1 \n",
    "    \n",
    "    return dic_freq"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:49:01.062137600Z",
     "start_time": "2023-10-25T02:49:01.052667300Z"
    }
   },
   "id": "c243c6b045e2e023"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "709"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia_ngram(bigram)[('Rio','Janeiro')]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:49:41.775477700Z",
     "start_time": "2023-10-25T02:49:39.590948500Z"
    }
   },
   "id": "4e1d57617ff75b8b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "F)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aee1752b3a30199"
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1384866\n",
      "1437356\n"
     ]
    }
   ],
   "source": [
    "trigram = generate_ngrams(c,3)\n",
    "print(len(set(trigram)))\n",
    "print(len(trigram))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:51:22.577066200Z",
     "start_time": "2023-10-25T02:51:21.417489200Z"
    }
   },
   "id": "a4c0046da9ca7267"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "trigram_fre = frequencia_ngram(trigram)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:52:04.199249400Z",
     "start_time": "2023-10-25T02:52:01.498731100Z"
    }
   },
   "id": "8d83a1e940ad308"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Obra', 'Completa', 'Machado') 144\n"
     ]
    }
   ],
   "source": [
    "maior = 0\n",
    "maior_nome = ''\n",
    "for i in trigram_fre:\n",
    "    if maior < trigram_fre[i]:\n",
    "        maior = trigram_fre[i]\n",
    "        maior_nome = i\n",
    "print(maior_nome, maior)        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-25T02:54:40.273896400Z",
     "start_time": "2023-10-25T02:54:39.788381700Z"
    }
   },
   "id": "a82477e31570c612"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
