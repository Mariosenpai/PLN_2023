{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-13T22:18:00.894374100Z",
     "start_time": "2023-10-13T22:18:00.880880500Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import nltk\n",
    "from nltk.lm.models import Lidstone\n",
    "from nltk.lm.models import Laplace\n",
    "from nltk.corpus import machado\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 - Para o trecho do poema \"Ainda que mal\"\n",
    "\"ainda que mal pergunte\n",
    "ainda que mal respondas\n",
    "ainda que mal te entenda\n",
    "ainda que mal repitas\"\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f49a6421188f439"
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n):\n",
    "    words = text.split()\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - n + 1):\n",
    "        bigram =  \" \".join(words[i:i+n]) \n",
    "        bigrams.append(tuple(bigram.split())) \n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "def probabilidade_verso( text,model, mostrar=False):\n",
    "    # Sequência de palavras\n",
    "    if type(text) == str:\n",
    "        sequence = tuple(text.split())\n",
    "    else:\n",
    "        sequence = text\n",
    "    \n",
    "    # Inicialize a probabilidade comum com 1.0 (inicialmente, multiplicamos por 1)\n",
    "    common_probability = 1.0\n",
    "    \n",
    "    # Calcular a probabilidade comum\n",
    "    for i in range(len(sequence) - 1):\n",
    "        gram = sequence[i]\n",
    "        #if mostrar:print(sequence[i])\n",
    "        print(gram )\n",
    "        if gram in model.vocab :\n",
    "            common_probability *= model.score(gram)\n",
    "        else:\n",
    "            # Se o bigrama não estiver no corpus, defina a probabilidade como 0\n",
    "            common_probability = 0.0\n",
    "            break  # Saia do loop se encontrar um bigrama ausente\n",
    "    \n",
    "    # Imprimir a probabilidade comum\n",
    "    if mostrar: print(f'Probabilidade Comum da Sequência: {common_probability:.10f}')\n",
    "    return common_probability\n",
    "\n",
    "def entropia(prob):\n",
    "    return prob * math.log2(prob)\n",
    "\n",
    "def perplexidade(frase,model):\n",
    "\n",
    "    common_probability = probabilidade_verso(frase,model, False)\n",
    "    \n",
    "    perplexity = 1\n",
    "    \n",
    "    if common_probability != 0.0:\n",
    "        perplexity = pow(2, entropia(common_probability))\n",
    "        \n",
    "    print(f'Perplexidade do Modelo: {perplexity:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T22:42:27.163600200Z",
     "start_time": "2023-10-13T22:42:27.144837Z"
    }
   },
   "id": "cf22856880f2a6a1"
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "text = (\"ainda que mal pergunte \"\n",
    "        \"ainda que mal respondas \"\n",
    "        \"ainda que mal te entenda \"\n",
    "        \"ainda que mal repitas\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T22:17:44.923138300Z"
    }
   },
   "id": "4a893a8c4fb825d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "a) Ache todos os bigramas do trecho"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fe695091dee7b38"
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ainda', 'que'), ('que', 'mal'), ('mal', 'pergunte'), ('pergunte', 'ainda'), ('ainda', 'que'), ('que', 'mal'), ('mal', 'respondas'), ('respondas', 'ainda'), ('ainda', 'que'), ('que', 'mal'), ('mal', 'te'), ('te', 'entenda'), ('entenda', 'ainda'), ('ainda', 'que'), ('que', 'mal'), ('mal', 'repitas')]\n"
     ]
    }
   ],
   "source": [
    "bi = generate_ngrams(text, 2)\n",
    "print(bi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T22:35:27.099150500Z",
     "start_time": "2023-10-13T22:35:27.090787100Z"
    }
   },
   "id": "6d77c9578e1a1fa2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "b)Calcule a probabilidade logarítmica de cada bigrama encontrado"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e23b09c96cdc3fdd"
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de ('ainda', 'que'): 0.21052631578947367\n",
      "Probabilidade de ('que', 'mal'): 0.21052631578947367\n",
      "Probabilidade de ('mal', 'pergunte'): 0.21052631578947367\n",
      "Probabilidade de ('pergunte', 'ainda'): 0.05263157894736842\n",
      "Probabilidade de ('ainda', 'que'): 0.21052631578947367\n",
      "Probabilidade de ('que', 'mal'): 0.21052631578947367\n",
      "Probabilidade de ('mal', 'respondas'): 0.21052631578947367\n",
      "Probabilidade de ('respondas', 'ainda'): 0.05263157894736842\n",
      "Probabilidade de ('ainda', 'que'): 0.21052631578947367\n",
      "Probabilidade de ('que', 'mal'): 0.21052631578947367\n",
      "Probabilidade de ('mal', 'te'): 0.21052631578947367\n",
      "Probabilidade de ('te', 'entenda'): 0.05263157894736842\n",
      "Probabilidade de ('entenda', 'ainda'): 0.05263157894736842\n",
      "Probabilidade de ('ainda', 'que'): 0.21052631578947367\n",
      "Probabilidade de ('que', 'mal'): 0.21052631578947367\n",
      "Probabilidade de ('mal', 'repitas'): 0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(text)]\n",
    "n = 2\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "model = MLE(n)\n",
    "model.fit(train_data, padded_sents)\n",
    "\n",
    "for i in bi:\n",
    "    print(f'Probabilidade de {i}: {probabilidade_verso(i,model)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T22:36:30.544364300Z",
     "start_time": "2023-10-13T22:36:30.536068300Z"
    }
   },
   "id": "8e8a53633e3ecd39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "d) Com o modelo de linguagem generalizado, calcule a probabilidade comum do verso \"ainda que mal insista\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6013588ed6f0b852"
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ainda\n",
      "que\n",
      "mal\n",
      "Probabilidade Comum da Sequência: 0.0093308062\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.009330806239976671"
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilidade_verso('ainda que mal insista',model, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T22:41:02.013326600Z",
     "start_time": "2023-10-13T22:41:01.990635600Z"
    }
   },
   "id": "b5a21e30d6577dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "e) Calcule a perplexidade do modelo de linguagem generalizado utilizando o verso \"ainda que mal insista” como conjunto de teste."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb11b8fe8a54e4cc"
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ainda\n",
      "que\n",
      "mal\n",
      "Perplexidade do Modelo: 0.9573\n"
     ]
    }
   ],
   "source": [
    "perplexidade('ainda que mal insista', model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T22:42:30.600476600Z",
     "start_time": "2023-10-13T22:42:30.591041100Z"
    }
   },
   "id": "50e61f110877e08c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Escolha um conjunto de textos  (poemas, letras de música, etc )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d780e36ebed82470"
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "def criar_modelo(text,n, model=None, gamma=0.1):\n",
    "    tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(text)]\n",
    "    train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "    \n",
    "    if model == 'li':\n",
    "        model_machado = Lidstone(gamma,order=n )\n",
    "    elif model == 'la':\n",
    "        model_machado = Laplace(order=n)\n",
    "    else:\n",
    "        model_machado = MLE(n)\n",
    "        \n",
    "    model_machado.fit(train_data, padded_sents)\n",
    "    return model_machado\n",
    "\n",
    "def remover_stopwords(texto):\n",
    "    # Carregue a lista de stopwords da língua desejada (exemplo: português)\n",
    "    stopwords_lista = nltk.corpus.stopwords.words('portuguese')\n",
    "    \n",
    "    # Tokenize o texto em palavras\n",
    "    palavras = word_tokenize(texto)\n",
    "    \n",
    "    # Crie uma lista de palavras sem as stopwords\n",
    "    palavras_sem_stopwords = [palavra for palavra in palavras if palavra.lower() not in stopwords_lista]\n",
    "    \n",
    "    # Recrie o texto sem as stopwords\n",
    "    texto_sem_stopwords = ' '.join(palavras_sem_stopwords)\n",
    "    \n",
    "    return texto_sem_stopwords\n",
    "\n",
    "def remocao_caracteres_especiais(text):\n",
    "    padrao = r'[^\\w\\s]?\\n'\n",
    "    return re.sub(padrao, ' ', text)\n",
    "\n",
    "def trans_corpus_text(corpus):\n",
    "    text = ''\n",
    "    for i in corpus:\n",
    "        text += machado.raw(i) +' '\n",
    "    \n",
    "    #Pre-processamento\n",
    "    #text = remover_stopwords(text)\n",
    "    text = remocao_caracteres_especiais(text)\n",
    "    \n",
    "    return text\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T22:16:30.820857200Z",
     "start_time": "2023-10-13T22:16:30.805204100Z"
    }
   },
   "id": "ed649a3dac523dee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "a) Separe 10% dos textos como conjunto de testes e e o restante como conjunto de treinamento"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50fd0399fd3057d7"
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento =  221\n",
      "Teste =  25\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "separa_treino = 0.1\n",
    "\n",
    "for i in machado.fileids():\n",
    "        corpus.append(i)\n",
    "\n",
    "tam_treinamento = math.ceil(len(corpus) * separa_treino)\n",
    "corpus_teste = []\n",
    "\n",
    "for i, t in enumerate(corpus):\n",
    "    if i == tam_treinamento:break\n",
    "    corpus_teste.append(t)\n",
    "    corpus.remove(t)\n",
    "\n",
    "print('Treinamento = ',len(corpus))\n",
    "print('Teste = ', len(corpus_teste))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T21:32:19.711555200Z",
     "start_time": "2023-10-13T21:32:19.658312700Z"
    }
   },
   "id": "c44b958182e83fb1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transforma o conjunto de teste me uma lista de n-grams"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b14faf94f5e3369a"
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "ugt = generate_ngrams(trans_corpus_text(corpus_teste),1)\n",
    "bgt = generate_ngrams(trans_corpus_text(corpus_teste),2)\n",
    "tgt = generate_ngrams(trans_corpus_text(corpus_teste),3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T21:57:58.321740900Z",
     "start_time": "2023-10-13T21:57:57.747118600Z"
    }
   },
   "id": "b586f9440890e726"
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) Construa um modelo de linguagen  explorando diferentes n-gramas (unigrama, bigrama e trigrama) e métodos de suavização (Laplace vs Lidstone)\n",
    "c) Faça uma análise do melhor modelo de linguagem com base na sua perplexidade no conjunto de teste"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3968b463613f79b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LIDSTONE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe1c45e42681cad4"
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "model_unigram_li = criar_modelo(trans_corpus_text(corpus), 1, model='li')\n",
    "model_bigram_li  = criar_modelo(trans_corpus_text(corpus), 2, model='li')\n",
    "model_trigram_li  = criar_modelo(trans_corpus_text(corpus), 3, model='li')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T21:41:34.586162100Z",
     "start_time": "2023-10-13T21:40:10.617090600Z"
    }
   },
   "id": "869bf0b45fa1da23"
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexicidade unigram Lidstone:  10894.325853126034\n",
      "Perplexicidade bigram Lidstone:  8572.914977396873\n",
      "Perplexicidade trigram Lidstone:  38011.19129848849\n"
     ]
    }
   ],
   "source": [
    "print('Perplexicidade unigram Lidstone: ',  model_unigram_li.perplexity(ugt)) \n",
    "print('Perplexicidade bigram Lidstone: ', model_bigram_li.perplexity(bgt))\n",
    "print('Perplexicidade trigram Lidstone: ', model_trigram_li.perplexity(tgt))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T21:58:03.583413400Z",
     "start_time": "2023-10-13T21:58:00.189413900Z"
    }
   },
   "id": "4390f656c4719b21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LAPLACE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a381795b68223e04"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "model_unigram_la = criar_modelo(trans_corpus_text(corpus), 1, model='la')\n",
    "model_bigram_la = criar_modelo(trans_corpus_text(corpus), 2,model='la')\n",
    "model_trigram_la = criar_modelo(trans_corpus_text(corpus), 3,model='la')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-13T21:12:01.790403500Z"
    }
   },
   "id": "bab7a55400c0da4b"
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexicidade unigram Laplace:  7069.282189140654\n",
      "Perplexicidade bigram Laplace:  14897.096413179352\n",
      "Perplexicidade trigram Laplace:  52537.56758533888\n"
     ]
    }
   ],
   "source": [
    "print('Perplexicidade unigram Laplace: ',  model_unigram_la.perplexity(ugt) ) \n",
    "print('Perplexicidade bigram Laplace: ', model_bigram_la.perplexity(bgt))\n",
    "print('Perplexicidade trigram Laplace: ', model_trigram_la.perplexity(tgt))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T22:05:14.059040Z",
     "start_time": "2023-10-13T22:05:11.024215200Z"
    }
   },
   "id": "52b9b4bbad790d61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "d) Escolha o melhor modelo e gere um texto de até 30 tokens predizendo a proxima palavra de maxima probabilidade."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2d0639f51bced63"
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amor que vem isto pacheco eu não posso perder um compasso que abria as velas rasgadas e minuciosamente examinadas os infelizes e entulhar o buraco estava tapado mas não havendo ninguém imaginei que \n"
     ]
    }
   ],
   "source": [
    "en = 'amor que vem'\n",
    "t = f'{en} '\n",
    "for i in model_trigram_la.generate(30, text_seed=en.split()):\n",
    "    t += i + ' '\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T23:00:20.744650400Z",
     "start_time": "2023-10-13T23:00:20.706650700Z"
    }
   },
   "id": "eae50f4f086f824a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
